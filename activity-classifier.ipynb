{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "    ## Activity based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] This commercial license of GraphLab Create is assigned to mjdata@mindjet.com.\n",
      "\n",
      "[INFO] Start server at: ipc:///tmp/graphlab_server-527 - Server binary: /Library/Python/2.7/site-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1440517449.log\n",
      "[INFO] GraphLab Server Version: 1.5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Finished parsing file /Users/mhardas/Google Drive/work/project/twitter-data-challenge/data/user_login_info.csv\n",
      "PROGRESS: Parsing completed. Parsed 100 lines in 3.71544 secs.\n",
      "------------------------------------------------------\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[int,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "PROGRESS: Read 3172097 lines. Lines per second: 1.01122e+06\n",
      "PROGRESS: Finished parsing file /Users/mhardas/Google Drive/work/project/twitter-data-challenge/data/user_login_info.csv\n",
      "PROGRESS: Parsing completed. Parsed 4000000 lines in 3.48858 secs.\n",
      "+---------+------------+----------------+-------------+----------+\n",
      "| user_id | country_id | primary_device | days_active | activity |\n",
      "+---------+------------+----------------+-------------+----------+\n",
      "|    1    |     h      |       B        |      26     |    t     |\n",
      "|    2    |     d      |       B        |      27     |    t     |\n",
      "|    3    |     h      |       A        |      21     |    t     |\n",
      "|    4    |     h      |       A        |      29     |    t     |\n",
      "|    5    |     h      |       E        |      30     |    f     |\n",
      "|    6    |     h      |       B        |      26     |    t     |\n",
      "|    7    |     g      |       B        |      30     |    t     |\n",
      "|    8    |     g      |       B        |      30     |    t     |\n",
      "|    9    |     h      |       A        |      30     |    t     |\n",
      "|    10   |     h      |       A        |      22     |    t     |\n",
      "+---------+------------+----------------+-------------+----------+\n",
      "[4000000 rows x 5 columns]\n",
      "Note: Only the head of the SFrame is printed.\n",
      "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "login = gl.SFrame('data/user_login_info.csv')\n",
    "print login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into 80/20 training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_login, test_login = login.random_split(0.8, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a binary classifier model of type BoostedTreesClassifier using gradient boosted trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: Boosted trees classifier:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 3040523\n",
      "PROGRESS: Number of classes           : 2\n",
      "PROGRESS: Number of feature columns   : 3\n",
      "PROGRESS: Number of unpacked features : 3\n",
      "PROGRESS: Starting Boosted Trees\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS:   Iter      Accuracy          Elapsed time\n",
      "PROGRESS:         (training) (validation)\n",
      "PROGRESS:      0   8.233e-01   8.230e-01        2.54s\n",
      "PROGRESS:      1   8.246e-01   8.243e-01        4.92s\n",
      "PROGRESS:      2   8.243e-01   8.241e-01        7.49s\n",
      "PROGRESS:      3   8.247e-01   8.245e-01        9.85s\n",
      "PROGRESS:      4   8.246e-01   8.244e-01       12.23s\n",
      "PROGRESS:      5   8.248e-01   8.243e-01       14.69s\n",
      "PROGRESS:      6   8.248e-01   8.244e-01       17.87s\n",
      "PROGRESS:      7   8.249e-01   8.247e-01       21.70s\n",
      "PROGRESS:      8   8.249e-01   8.245e-01       24.63s\n",
      "PROGRESS:      9   8.250e-01   8.246e-01       27.15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Class                         : BoostedTreesClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Number of examples            : 3040523\n",
       "Number of classes             : 2\n",
       "Number of feature columns     : 3\n",
       "Number of unpacked features   : 3\n",
       "\n",
       "Settings\n",
       "--------\n",
       "Number of trees               : 10\n",
       "Max tree depth                : 6\n",
       "Train accuracy                : 0.825\n",
       "Validation accuracy           : 0.8246\n",
       "Training time (sec)           : 28.8072"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['country_id', 'primary_device', 'days_active']\n",
    "model_login = gl.boosted_trees_classifier.create(\n",
    "            train_login,\n",
    "            target='activity',\n",
    "            features=features,\n",
    "            max_iterations=10)\n",
    "\n",
    "model_login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalue with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8248556344456588, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tstr\n",
       " \tpredicted_label\tstr\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+--------+\n",
       " | target_label | predicted_label | count  |\n",
       " +--------------+-----------------+--------+\n",
       " |      f       |        f        | 44735  |\n",
       " |      t       |        f        | 28345  |\n",
       " |      t       |        t        | 614907 |\n",
       " |      f       |        t        | 111719 |\n",
       " +--------------+-----------------+--------+\n",
       " [4 rows x 3 columns]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_login = model_login.evaluate(test_login)\n",
    "res_login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of false positives. Many people who are actually inactive are being classified as active. Lets see if we can improve the classifier accuracy by bringing in some more activity based data from other source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Finished parsing file /Users/mhardas/Google Drive/work/project/twitter-data-challenge/data/user_engagement.csv\n",
      "PROGRESS: Parsing completed. Parsed 100 lines in 1.49689 secs.\n",
      "------------------------------------------------------\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[int,int,int,int,int,int,int,int,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "PROGRESS: Read 1737129 lines. Lines per second: 736271\n",
      "PROGRESS: Finished parsing file /Users/mhardas/Google Drive/work/project/twitter-data-challenge/data/user_engagement.csv\n",
      "PROGRESS: Parsing completed. Parsed 4000000 lines in 3.35627 secs.\n",
      "+---------+------------+----------------+-------------+----------+----------------+\n",
      "| user_id | country_id | primary_device | days_active | activity | num_tweets_30d |\n",
      "+---------+------------+----------------+-------------+----------+----------------+\n",
      "|    1    |     h      |       B        |      26     |    t     |      186       |\n",
      "|    2    |     d      |       B        |      27     |    t     |       5        |\n",
      "|    3    |     h      |       A        |      21     |    t     |       0        |\n",
      "|    4    |     h      |       A        |      29     |    t     |       4        |\n",
      "|    5    |     h      |       E        |      30     |    f     |       1        |\n",
      "|    6    |     h      |       B        |      26     |    t     |       51       |\n",
      "|    7    |     g      |       B        |      30     |    t     |      4713      |\n",
      "|    8    |     g      |       B        |      30     |    t     |       5        |\n",
      "|    9    |     h      |       A        |      30     |    t     |      185       |\n",
      "|    10   |     h      |       A        |      22     |    t     |       0        |\n",
      "+---------+------------+----------------+-------------+----------+----------------+\n",
      "+--------------------+-----------------+------------------------+-------------------------+\n",
      "| num_tweet_days_30d | time_in_app_30d | num_timeline_views_30d | num_share_sent_days_30d |\n",
      "+--------------------+-----------------+------------------------+-------------------------+\n",
      "|         24         |      14109      |          806           |            19           |\n",
      "|         5          |       2114      |           85           |            4            |\n",
      "|         0          |        0        |           32           |            0            |\n",
      "|         3          |      12654      |          595           |            1            |\n",
      "|         1          |        0        |          1335          |            0            |\n",
      "|         14         |      10729      |          262           |            11           |\n",
      "|         29         |      14546      |          649           |            28           |\n",
      "|         5          |       1993      |          518           |            5            |\n",
      "|         26         |       3030      |          157           |            17           |\n",
      "|         0          |       5683      |          274           |            0            |\n",
      "+--------------------+-----------------+------------------------+-------------------------+\n",
      "+--------------------+---------------------+---------------------+\n",
      "| num_share_rcvd_30d | num_favour_sent_30d | num_favour_rcvd_30d |\n",
      "+--------------------+---------------------+---------------------+\n",
      "|         7          |         111         |          27         |\n",
      "|         0          |          1          |          0          |\n",
      "|         0          |          0          |          0          |\n",
      "|         0          |          6          |          0          |\n",
      "|         0          |          0          |          0          |\n",
      "|         0          |         117         |          4          |\n",
      "|         0          |          3          |          4          |\n",
      "|         0          |          30         |          0          |\n",
      "|         16         |          13         |          12         |\n",
      "|         0          |          0          |          0          |\n",
      "+--------------------+---------------------+---------------------+\n",
      "[4000000 rows x 13 columns]\n",
      "Note: Only the head of the SFrame is printed.\n",
      "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n"
     ]
    }
   ],
   "source": [
    "eng = gl.SFrame.read_csv('data/user_engagement.csv')\n",
    "login_eng = login.join(eng, on='user_id', how='inner')\n",
    "print login_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_login_eng, test_login_eng = login_eng.random_split(0.8, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remodel classifier with entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: Boosted trees classifier:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 3040444\n",
      "PROGRESS: Number of classes           : 2\n",
      "PROGRESS: Number of feature columns   : 11\n",
      "PROGRESS: Number of unpacked features : 11\n",
      "PROGRESS: Starting Boosted Trees\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS:   Iter      Accuracy          Elapsed time\n",
      "PROGRESS:         (training) (validation)\n",
      "PROGRESS:      0   8.888e-01   8.890e-01       16.64s\n",
      "PROGRESS:      1   8.895e-01   8.896e-01       33.47s\n",
      "PROGRESS:      2   8.898e-01   8.897e-01       49.80s\n",
      "PROGRESS:      3   8.899e-01   8.899e-01       66.29s\n",
      "PROGRESS:      4   8.900e-01   8.901e-01       85.05s\n",
      "PROGRESS:      5   8.901e-01   8.901e-01      103.40s\n",
      "PROGRESS:      6   8.901e-01   8.901e-01      120.11s\n",
      "PROGRESS:      7   8.902e-01   8.902e-01      136.29s\n",
      "PROGRESS:      8   8.903e-01   8.904e-01      152.48s\n",
      "PROGRESS:      9   8.903e-01   8.904e-01      168.62s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Class                         : BoostedTreesClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Number of examples            : 3040444\n",
       "Number of classes             : 2\n",
       "Number of feature columns     : 11\n",
       "Number of unpacked features   : 11\n",
       "\n",
       "Settings\n",
       "--------\n",
       "Number of trees               : 10\n",
       "Max tree depth                : 6\n",
       "Train accuracy                : 0.8903\n",
       "Validation accuracy           : 0.8904\n",
       "Training time (sec)           : 174.9902"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=[\n",
    "    'country_id',\n",
    "    'primary_device',\n",
    "    'days_active',\n",
    "    'num_tweets_30d',\n",
    "    'num_tweet_days_30d',\n",
    "    'time_in_app_30d',\n",
    "    'num_timeline_views_30d',\n",
    "    'num_share_sent_days_30d',\n",
    "    'num_share_rcvd_30d',\n",
    "    'num_favour_sent_30d',\n",
    "    'num_favour_rcvd_30d'                \n",
    "]\n",
    "\n",
    "model_login_eng = gl.boosted_trees_classifier.create(\n",
    "            train_login_eng,\n",
    "            target='activity',\n",
    "            features=features,\n",
    "            max_iterations=10)\n",
    "\n",
    "model_login_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8896131828446954, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tstr\n",
       " \tpredicted_label\tstr\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+--------+\n",
       " | target_label | predicted_label | count  |\n",
       " +--------------+-----------------+--------+\n",
       " |      f       |        t        | 43870  |\n",
       " |      f       |        f        | 112584 |\n",
       " |      t       |        f        | 44407  |\n",
       " |      t       |        t        | 598845 |\n",
       " +--------------+-----------------+--------+\n",
       " [4 rows x 3 columns]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_login_eng = model_login_eng.evaluate(test_login_eng)\n",
    "res_login_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy improved from 0.82 to 0.88. This means it is a good idea to include the engagement data for training an activity classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now investigate if incorporating graph info into the training data increases accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Finished parsing file /Users/mhardas/Google Drive/work/project/twitter-data-challenge/data/user_graph.csv\n",
      "PROGRESS: Parsing completed. Parsed 100 lines in 1.50493 secs.\n",
      "------------------------------------------------------\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[int,int,int,int,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "PROGRESS: Read 2641306 lines. Lines per second: 1.11902e+06\n",
      "PROGRESS: Finished parsing file /Users/mhardas/Google Drive/work/project/twitter-data-challenge/data/user_graph.csv\n",
      "PROGRESS: Parsing completed. Parsed 4000000 lines in 2.70403 secs.\n",
      "+---------+------------+----------------+-------------+----------+----------------+\n",
      "| user_id | country_id | primary_device | days_active | activity | num_tweets_30d |\n",
      "+---------+------------+----------------+-------------+----------+----------------+\n",
      "|    1    |     h      |       B        |      26     |    t     |      186       |\n",
      "|    2    |     d      |       B        |      27     |    t     |       5        |\n",
      "|    3    |     h      |       A        |      21     |    t     |       0        |\n",
      "|    4    |     h      |       A        |      29     |    t     |       4        |\n",
      "|    5    |     h      |       E        |      30     |    f     |       1        |\n",
      "|    6    |     h      |       B        |      26     |    t     |       51       |\n",
      "|    7    |     g      |       B        |      30     |    t     |      4713      |\n",
      "|    8    |     g      |       B        |      30     |    t     |       5        |\n",
      "|    9    |     h      |       A        |      30     |    t     |      185       |\n",
      "|    10   |     h      |       A        |      22     |    t     |       0        |\n",
      "+---------+------------+----------------+-------------+----------+----------------+\n",
      "+--------------------+-----------------+------------------------+-------------------------+\n",
      "| num_tweet_days_30d | time_in_app_30d | num_timeline_views_30d | num_share_sent_days_30d |\n",
      "+--------------------+-----------------+------------------------+-------------------------+\n",
      "|         24         |      14109      |          806           |            19           |\n",
      "|         5          |       2114      |           85           |            4            |\n",
      "|         0          |        0        |           32           |            0            |\n",
      "|         3          |      12654      |          595           |            1            |\n",
      "|         1          |        0        |          1335          |            0            |\n",
      "|         14         |      10729      |          262           |            11           |\n",
      "|         29         |      14546      |          649           |            28           |\n",
      "|         5          |       1993      |          518           |            5            |\n",
      "|         26         |       3030      |          157           |            17           |\n",
      "|         0          |       5683      |          274           |            0            |\n",
      "+--------------------+-----------------+------------------------+-------------------------+\n",
      "+--------------------+---------------------+---------------------+-----------+\n",
      "| num_share_rcvd_30d | num_favour_sent_30d | num_favour_rcvd_30d | followers |\n",
      "+--------------------+---------------------+---------------------+-----------+\n",
      "|         7          |         111         |          27         |    144    |\n",
      "|         0          |          1          |          0          |     90    |\n",
      "|         0          |          0          |          0          |     2     |\n",
      "|         0          |          6          |          0          |     21    |\n",
      "|         0          |          0          |          0          |     1     |\n",
      "|         0          |         117         |          4          |     21    |\n",
      "|         0          |          3          |          4          |    247    |\n",
      "|         0          |          30         |          0          |    266    |\n",
      "|         16         |          13         |          12         |    964    |\n",
      "|         0          |          0          |          0          |    180    |\n",
      "+--------------------+---------------------+---------------------+-----------+\n",
      "+------------+------------------+-------------------------------+\n",
      "| followings | active_followers | num_mutual_follower_added_30d |\n",
      "+------------+------------------+-------------------------------+\n",
      "|    139     |       134        |               10              |\n",
      "|    435     |        78        |               16              |\n",
      "|     14     |        0         |               0               |\n",
      "|    131     |        13        |               1               |\n",
      "|     59     |        0         |               1               |\n",
      "|    117     |        19        |               2               |\n",
      "|    500     |       190        |               17              |\n",
      "|    363     |       212        |               28              |\n",
      "|    728     |       599        |               6               |\n",
      "|    718     |       117        |               0               |\n",
      "+------------+------------------+-------------------------------+\n",
      "[3919937 rows x 17 columns]\n",
      "Note: Only the head of the SFrame is printed.\n",
      "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n"
     ]
    }
   ],
   "source": [
    "graph = gl.SFrame.read_csv('data/user_graph.csv')\n",
    "login_eng_graph = login_eng.join(graph, on='user_id', how='inner')\n",
    "login_eng_graph = login_eng_graph.dropna()\n",
    "login_eng_graph = login_eng_graph.fillna('followers', 0).fillna('followings',0).fillna('active_followers',0).fillna('num_mutual_follower_added_30d', 0)\n",
    "print login_eng_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: Boosted trees classifier:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 2979713\n",
      "PROGRESS: Number of classes           : 2\n",
      "PROGRESS: Number of feature columns   : 15\n",
      "PROGRESS: Number of unpacked features : 15\n",
      "PROGRESS: Starting Boosted Trees\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS:   Iter      Accuracy          Elapsed time\n",
      "PROGRESS:         (training) (validation)\n",
      "PROGRESS:      0   8.920e-01   8.917e-01       26.26s\n",
      "PROGRESS:      1   8.930e-01   8.934e-01       52.25s\n",
      "PROGRESS:      2   8.932e-01   8.936e-01       77.23s\n",
      "PROGRESS:      3   8.933e-01   8.934e-01      102.58s\n",
      "PROGRESS:      4   8.934e-01   8.935e-01      126.54s\n",
      "PROGRESS:      5   8.935e-01   8.936e-01      151.16s\n",
      "PROGRESS:      6   8.939e-01   8.939e-01      176.11s\n",
      "PROGRESS:      7   8.940e-01   8.941e-01      200.98s\n",
      "PROGRESS:      8   8.940e-01   8.940e-01      225.11s\n",
      "PROGRESS:      9   8.940e-01   8.941e-01      249.11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Class                         : BoostedTreesClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Number of examples            : 2979713\n",
       "Number of classes             : 2\n",
       "Number of feature columns     : 15\n",
       "Number of unpacked features   : 15\n",
       "\n",
       "Settings\n",
       "--------\n",
       "Number of trees               : 10\n",
       "Max tree depth                : 6\n",
       "Train accuracy                : 0.894\n",
       "Validation accuracy           : 0.8941\n",
       "Training time (sec)           : 257.1845"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=[\n",
    "    'country_id',\n",
    "    'primary_device',\n",
    "    'days_active',\n",
    "    'num_tweets_30d',\n",
    "    'num_tweet_days_30d',\n",
    "    'time_in_app_30d',\n",
    "    'num_timeline_views_30d',\n",
    "    'num_share_sent_days_30d',\n",
    "    'num_share_rcvd_30d',\n",
    "    'num_favour_sent_30d',\n",
    "    'num_favour_rcvd_30d',\n",
    "    'followers',\n",
    "    'followings',\n",
    "    'active_followers',\n",
    "    'num_mutual_follower_added_30d'\n",
    "    ]\n",
    "\n",
    "train_login_eng_graph, test_login_eng_graph = login_eng_graph.random_split(0.8, seed=1)\n",
    "model_login_eng_graph = gl.boosted_trees_classifier.create(\n",
    "            train_login_eng_graph,\n",
    "            target='activity',\n",
    "            features=features,\n",
    "            max_iterations=10)\n",
    "\n",
    "model_login_eng_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8939041978838275, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tstr\n",
       " \tpredicted_label\tstr\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+--------+\n",
       " | target_label | predicted_label | count  |\n",
       " +--------------+-----------------+--------+\n",
       " |      f       |        f        | 102000 |\n",
       " |      f       |        t        | 42482  |\n",
       " |      t       |        f        | 40643  |\n",
       " |      t       |        t        | 598365 |\n",
       " +--------------+-----------------+--------+\n",
       " [4 rows x 3 columns]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_login_eng_graph = model_login_eng_graph.evaluate(test_login_eng_graph)\n",
    "res_login_eng_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy marginally increased from 0.88 tp 0.894. It is very small improvement which may or may not be attributed to user graph data. Let us try to figure out if we can further increase the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection and engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that engagement metrics are the most informative metrics about activity. So we drop all features from user login info and user graph and select on the engagement metrics to build the model.\n",
    "\n",
    "Feature hasher is a method in the graphlab package that we can use to engineer useful predictor metrics from existing engagement metrics to see if they are more informative. Basic idea of feature hashing is to collaps a feature vector by reducing the dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: Boosted trees classifier:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 2978510\n",
      "PROGRESS: Number of classes           : 2\n",
      "PROGRESS: Number of feature columns   : 9\n",
      "PROGRESS: Number of unpacked features : 16\n",
      "PROGRESS: Starting Boosted Trees\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS:   Iter      Accuracy          Elapsed time\n",
      "PROGRESS:         (training) (validation)\n",
      "PROGRESS:      0   8.921e-01   8.918e-01       27.22s\n",
      "PROGRESS:      1   8.922e-01   8.920e-01       52.87s\n",
      "PROGRESS:      2   8.930e-01   8.927e-01       78.01s\n",
      "PROGRESS:      3   8.932e-01   8.933e-01      101.72s\n",
      "PROGRESS:      4   8.933e-01   8.936e-01      125.20s\n",
      "PROGRESS:      5   8.933e-01   8.938e-01      148.90s\n",
      "PROGRESS:      6   8.936e-01   8.938e-01      172.65s\n",
      "PROGRESS:      7   8.938e-01   8.940e-01      196.44s\n",
      "PROGRESS:      8   8.939e-01   8.941e-01      220.12s\n",
      "PROGRESS:      9   8.941e-01   8.942e-01      243.75s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8939557233742773, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tstr\n",
       " \tpredicted_label\tstr\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+--------+\n",
       " | target_label | predicted_label | count  |\n",
       " +--------------+-----------------+--------+\n",
       " |      f       |        t        | 42427  |\n",
       " |      f       |        f        | 102728 |\n",
       " |      t       |        f        | 40815  |\n",
       " |      t       |        t        | 599004 |\n",
       " +--------------+-----------------+--------+\n",
       " [4 rows x 3 columns]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphlab import feature_engineering as fe\n",
    "\n",
    "simple_features=[\n",
    "    'num_tweets_30d',\n",
    "    'num_tweet_days_30d',\n",
    "    'time_in_app_30d',\n",
    "    'num_timeline_views_30d',\n",
    "    'num_share_sent_days_30d',\n",
    "    'num_share_rcvd_30d',\n",
    "    'num_favour_sent_30d',\n",
    "    'num_favour_rcvd_30d'\n",
    "    ]\n",
    "\n",
    "train_login_eng_graph, test_login_eng_graph = login_eng_graph.random_split(0.8, seed=12345)\n",
    "\n",
    "hasher = fe.create(login_eng_graph, fe.FeatureHasher(features=simple_features))\n",
    "hashed_train_login_eng_graph = hasher.transform(train_login_eng_graph)\n",
    "hashed_test_login_eng_graph = hasher.transform(test_login_eng_graph)\n",
    "training_features = simple_features.append('hashed_features')\n",
    "\n",
    "model_login_eng_graph = gl.boosted_trees_classifier.create(\n",
    "            hashed_train_login_eng_graph,\n",
    "            target='activity',\n",
    "            features=training_features,\n",
    "            max_iterations=10)\n",
    "\n",
    "res_login_eng_graph = model_login_eng_graph.evaluate(hashed_test_login_eng_graph)\n",
    "res_login_eng_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The accuracy marginally increased to 0.894. The false positives decreased to 42427 from 42484."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: Boosted trees classifier:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 2978051\n",
      "PROGRESS: Number of classes           : 2\n",
      "PROGRESS: Number of feature columns   : 17\n",
      "PROGRESS: Number of unpacked features : 52\n",
      "PROGRESS: Starting Boosted Trees\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS:   Iter      Accuracy          Elapsed time\n",
      "PROGRESS:         (training) (validation)\n",
      "PROGRESS:      0   8.917e-01   8.915e-01       86.25s\n",
      "PROGRESS:      1   8.919e-01   8.918e-01      173.40s\n",
      "PROGRESS:      2   8.930e-01   8.931e-01      260.83s\n",
      "PROGRESS:      3   8.930e-01   8.932e-01      347.17s\n",
      "PROGRESS:      4   8.935e-01   8.936e-01      431.57s\n",
      "PROGRESS:      5   8.934e-01   8.934e-01      515.97s\n",
      "PROGRESS:      6   8.936e-01   8.936e-01      601.44s\n",
      "PROGRESS:      7   8.937e-01   8.937e-01      685.86s\n",
      "PROGRESS:      8   8.939e-01   8.938e-01      771.13s\n",
      "PROGRESS:      9   8.939e-01   8.939e-01      858.47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8938283306198677, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tstr\n",
       " \tpredicted_label\tstr\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+--------+\n",
       " | target_label | predicted_label | count  |\n",
       " +--------------+-----------------+--------+\n",
       " |      f       |        t        | 42812  |\n",
       " |      f       |        f        | 102343 |\n",
       " |      t       |        f        | 40530  |\n",
       " |      t       |        t        | 599289 |\n",
       " +--------------+-----------------+--------+\n",
       " [4 rows x 3 columns]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphlab import feature_engineering as fe\n",
    "\n",
    "simple_features=[\n",
    "    'num_tweets_30d',\n",
    "    'num_tweet_days_30d',\n",
    "    'time_in_app_30d',\n",
    "    'num_timeline_views_30d',\n",
    "    'num_share_sent_days_30d',\n",
    "    'num_share_rcvd_30d',\n",
    "    'num_favour_sent_30d',\n",
    "    'num_favour_rcvd_30d'\n",
    "    ]\n",
    "\n",
    "train_login_eng_graph, test_login_eng_graph = login_eng_graph.random_split(0.8, seed=12345)\n",
    "\n",
    "quad = fe.create(login_eng_graph, fe.QuadraticFeatures(features=simple_features))\n",
    "quad_train_login_eng_graph = quad.transform(train_login_eng_graph)\n",
    "quad_test_login_eng_graph = quad.transform(test_login_eng_graph)\n",
    "training_features = simple_features.append('quadratic_features')\n",
    "\n",
    "model_login_eng_graph_quad = gl.boosted_trees_classifier.create(\n",
    "            quad_train_login_eng_graph,\n",
    "            target='activity',\n",
    "            features=training_features,\n",
    "            max_iterations=10)\n",
    "\n",
    "res_login_eng_graph_quad = model_login_eng_graph_quad.evaluate(quad_test_login_eng_graph)\n",
    "res_login_eng_graph_quad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadratic Features is another method in the graphlab package that we can use to engineer useful predictor metrics from existing engagement metrics to see if they are more informative. Basic idea of quadratic features is to compute a feature which is the combination of all training features.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
